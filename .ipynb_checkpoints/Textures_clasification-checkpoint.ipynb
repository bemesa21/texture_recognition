{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.feature import greycomatrix\n",
    "from skimage.feature import greycoprops\n",
    "import image_slicer\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<Tile #1 - ladrillo_01_01.png>,\n",
       " <Tile #2 - ladrillo_01_02.png>,\n",
       " <Tile #3 - ladrillo_01_03.png>,\n",
       " <Tile #4 - ladrillo_01_04.png>,\n",
       " <Tile #5 - ladrillo_01_05.png>,\n",
       " <Tile #6 - ladrillo_01_06.png>,\n",
       " <Tile #7 - ladrillo_01_07.png>,\n",
       " <Tile #8 - ladrillo_01_08.png>,\n",
       " <Tile #9 - ladrillo_01_09.png>,\n",
       " <Tile #10 - ladrillo_02_01.png>,\n",
       " <Tile #11 - ladrillo_02_02.png>,\n",
       " <Tile #12 - ladrillo_02_03.png>,\n",
       " <Tile #13 - ladrillo_02_04.png>,\n",
       " <Tile #14 - ladrillo_02_05.png>,\n",
       " <Tile #15 - ladrillo_02_06.png>,\n",
       " <Tile #16 - ladrillo_02_07.png>,\n",
       " <Tile #17 - ladrillo_02_08.png>,\n",
       " <Tile #18 - ladrillo_02_09.png>,\n",
       " <Tile #19 - ladrillo_03_01.png>,\n",
       " <Tile #20 - ladrillo_03_02.png>,\n",
       " <Tile #21 - ladrillo_03_03.png>,\n",
       " <Tile #22 - ladrillo_03_04.png>,\n",
       " <Tile #23 - ladrillo_03_05.png>,\n",
       " <Tile #24 - ladrillo_03_06.png>,\n",
       " <Tile #25 - ladrillo_03_07.png>,\n",
       " <Tile #26 - ladrillo_03_08.png>,\n",
       " <Tile #27 - ladrillo_03_09.png>,\n",
       " <Tile #28 - ladrillo_04_01.png>,\n",
       " <Tile #29 - ladrillo_04_02.png>,\n",
       " <Tile #30 - ladrillo_04_03.png>,\n",
       " <Tile #31 - ladrillo_04_04.png>,\n",
       " <Tile #32 - ladrillo_04_05.png>,\n",
       " <Tile #33 - ladrillo_04_06.png>,\n",
       " <Tile #34 - ladrillo_04_07.png>,\n",
       " <Tile #35 - ladrillo_04_08.png>,\n",
       " <Tile #36 - ladrillo_04_09.png>,\n",
       " <Tile #37 - ladrillo_05_01.png>,\n",
       " <Tile #38 - ladrillo_05_02.png>,\n",
       " <Tile #39 - ladrillo_05_03.png>,\n",
       " <Tile #40 - ladrillo_05_04.png>,\n",
       " <Tile #41 - ladrillo_05_05.png>,\n",
       " <Tile #42 - ladrillo_05_06.png>,\n",
       " <Tile #43 - ladrillo_05_07.png>,\n",
       " <Tile #44 - ladrillo_05_08.png>,\n",
       " <Tile #45 - ladrillo_05_09.png>,\n",
       " <Tile #46 - ladrillo_06_01.png>,\n",
       " <Tile #47 - ladrillo_06_02.png>,\n",
       " <Tile #48 - ladrillo_06_03.png>,\n",
       " <Tile #49 - ladrillo_06_04.png>,\n",
       " <Tile #50 - ladrillo_06_05.png>,\n",
       " <Tile #51 - ladrillo_06_06.png>,\n",
       " <Tile #52 - ladrillo_06_07.png>,\n",
       " <Tile #53 - ladrillo_06_08.png>,\n",
       " <Tile #54 - ladrillo_06_09.png>,\n",
       " <Tile #55 - ladrillo_07_01.png>,\n",
       " <Tile #56 - ladrillo_07_02.png>,\n",
       " <Tile #57 - ladrillo_07_03.png>,\n",
       " <Tile #58 - ladrillo_07_04.png>,\n",
       " <Tile #59 - ladrillo_07_05.png>,\n",
       " <Tile #60 - ladrillo_07_06.png>,\n",
       " <Tile #61 - ladrillo_07_07.png>,\n",
       " <Tile #62 - ladrillo_07_08.png>,\n",
       " <Tile #63 - ladrillo_07_09.png>,\n",
       " <Tile #64 - ladrillo_08_01.png>,\n",
       " <Tile #65 - ladrillo_08_02.png>,\n",
       " <Tile #66 - ladrillo_08_03.png>,\n",
       " <Tile #67 - ladrillo_08_04.png>,\n",
       " <Tile #68 - ladrillo_08_05.png>,\n",
       " <Tile #69 - ladrillo_08_06.png>,\n",
       " <Tile #70 - ladrillo_08_07.png>,\n",
       " <Tile #71 - ladrillo_08_08.png>,\n",
       " <Tile #72 - ladrillo_08_09.png>,\n",
       " <Tile #73 - ladrillo_09_01.png>,\n",
       " <Tile #74 - ladrillo_09_02.png>,\n",
       " <Tile #75 - ladrillo_09_03.png>,\n",
       " <Tile #76 - ladrillo_09_04.png>,\n",
       " <Tile #77 - ladrillo_09_05.png>,\n",
       " <Tile #78 - ladrillo_09_06.png>,\n",
       " <Tile #79 - ladrillo_09_07.png>,\n",
       " <Tile #80 - ladrillo_09_08.png>,\n",
       " <Tile #81 - ladrillo_09_09.png>)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#image_slicer.slice('dataset/train/ladrillo/ladrillo.jpg', 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(image):\n",
    "    features = np.zeros(6)\n",
    "    # calculate haralick texture features for 4 types of adjacency\n",
    "    g = greycomatrix(image, [1], [0, np.pi/2], levels=256, normed=True, symmetric=True)\n",
    "    features[0] = greycoprops(g, 'contrast').mean()\n",
    "    features[1] = greycoprops(g, 'dissimilarity').mean()\n",
    "    features[2] = greycoprops(g, 'homogeneity').mean()\n",
    "    features[3] = greycoprops(g, 'ASM').mean()\n",
    "    features[4] = greycoprops(g, 'energy').mean()\n",
    "    features[5] = greycoprops(g, 'correlation').mean()\n",
    "    \n",
    "    return np.array(features)\n",
    "\n",
    "def load_training_dataset():\n",
    "    # load the training dataset\n",
    "    train_path  = \"dataset/train\"\n",
    "    train_names = os.listdir(train_path)\n",
    "\n",
    "    # empty list to hold feature vectors and train labels\n",
    "    train_features = []\n",
    "    train_labels   = []\n",
    "\n",
    "    # loop over the training dataset\n",
    "    print (\"[STATUS] Started extracting haralick textures..\")\n",
    "    for train_name in train_names:\n",
    "        cur_path = train_path + \"/\" + train_name\n",
    "        cur_label = train_name\n",
    "        i = 1\n",
    "\n",
    "        for file in glob.glob(cur_path + \"/*.png\"):\n",
    "            #print (\"Processing Image - {} in {}\".format(i, cur_label))\n",
    "            # read the training image\n",
    "            image = cv2.imread(file)\n",
    "\n",
    "            # convert the image to grayscale\n",
    "            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            # extract haralick texture from the image\n",
    "            features = extract_features(gray)\n",
    "\n",
    "            # append the feature vector and label\n",
    "            train_features.append(features)\n",
    "            train_labels.append(cur_label)\n",
    "            # show loop update\n",
    "            i += 1\n",
    "    return train_features, train_labels\n",
    "\n",
    "# loop over the test images\n",
    "\n",
    "def load_test_image(path_imagen):    \n",
    "    image = cv2.imread(path_imagen)\n",
    "    #cv2.imshow(\"Testing image \", image)\n",
    "    # convert to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    \n",
    "    # extract haralick texture from the image\n",
    "    features = extract_features(gray)\n",
    "    return image, features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_clasifier(X_train, y_train):\n",
    "    knn = KNeighborsClassifier(n_neighbors = 4)\n",
    "    knn = knn.fit(X_train, y_train)\n",
    "    print('Accuracy of K-NN classifier on training set: {:.2f}'\n",
    "      .format(knn.score(X_train, y_train)))\n",
    "    return knn\n",
    "\n",
    "def knn_predict(knn, image_name, image, features):\n",
    "    # evaluate the model and predict label\n",
    "    prediction = knn.predict(features.reshape(1, -1))[0]\n",
    "    print(\"Image: \" + image_name)\n",
    "    # show the label\n",
    "    #cv2.putText(image, prediction, (20,30), cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0,255,255), 3)\n",
    "    print (\"Prediction - {}\".format(prediction))\n",
    "    print('\\n')\n",
    "    #display the output image\n",
    "    #cv2.imshow(\"Test_Image\", image)\n",
    "    #cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def svm_classifier(X_train, y_train):\n",
    "    #create the classifier\n",
    "    print (\"[STATUS] Creating the classifier..\")\n",
    "    clf_svm = LinearSVC(random_state=9)\n",
    "\n",
    "    # fit the training data and labels\n",
    "    print (\"[STATUS] Fitting data/label to model..\")\n",
    "    return clf_svm.fit(X_train, y_train)\n",
    "    \n",
    "def svm_predict(svm, image_name, image, features):\n",
    "    # evaluate the model and predict label\n",
    "    prediction = svm.predict(features.reshape(1, -1))[0]\n",
    "    print(\"Image: \" + image_name)\n",
    "    # show the label\n",
    "    #cv2.putText(image, prediction, (20,30), cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0,255,255), 3)\n",
    "    print (\"Prediction - {}\".format(prediction))\n",
    "    print('\\n')\n",
    "    #display the output image\n",
    "    #cv2.imshow(\"Test_Image\", image)\n",
    "    #cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lda_classifier(X_train, y_train):\n",
    "    #create the classifier\n",
    "    print (\"[STATUS] Creating the classifier..\")\n",
    "    lda = LinearDiscriminantAnalysis()\n",
    "\n",
    "    # fit the training data and labels\n",
    "    print (\"[STATUS] Fitting data/label to model..\")\n",
    "    return lda.fit(X_train, y_train)\n",
    "    \n",
    "def lda_predict(lda, image_name, image, features):\n",
    "    # evaluate the model and predict label\n",
    "    print(features.reshape(1, -1))\n",
    "    prediction = lda.predict(features.reshape(1, -1))[0]\n",
    "    print(\"Image: \" + image_name)\n",
    "    # show the label\n",
    "    #cv2.putText(image, prediction, (20,30), cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0,255,255), 3)\n",
    "    print (\"Prediction - {}\".format(prediction))\n",
    "    print('\\n')\n",
    "    #display the output image\n",
    "    #cv2.imshow(\"Test_Image\", image)\n",
    "    #cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_all_images(classifier):\n",
    "    test_path = \"dataset/test\"\n",
    "    train_dataset, train_labels = load_training_dataset()\n",
    "    if(classifier == \"svm\"):\n",
    "        svm = svm_classifier(train_dataset, train_labels)\n",
    "        for file in glob.glob(test_path + \"/*.png\"):\n",
    "            print(file)\n",
    "            image, features = load_test_image(file)\n",
    "            prediction = svm_predict(svm, file, image, features)\n",
    "    elif(classifier == \"knn\"):\n",
    "        knn = knn_clasifier(train_dataset, train_labels)\n",
    "        for file in glob.glob(test_path + \"/*.png\"):\n",
    "            print(file)\n",
    "            image, features = load_test_image(file)\n",
    "            prediction = knn_predict(knn, file, image, features)\n",
    "    elif(classifier == \"lda\"):\n",
    "        lda = lda_classifier(train_dataset, train_labels)\n",
    "        for file in glob.glob(test_path + \"/*.png\"):\n",
    "            print(file)\n",
    "            image, features = load_test_image(file)\n",
    "            prediction = lda_predict(lda, file, image, features)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[STATUS] Started extracting haralick textures..\n",
      "[STATUS] Creating the classifier..\n",
      "[STATUS] Fitting data/label to model..\n",
      "dataset/test/ladrillo_01_01.png\n",
      "[[3.41838588e+02 9.27343514e+00 1.94682876e-01 7.59711848e-04\n",
      "  2.74087113e-02 9.50736801e-01]]\n",
      "Image: dataset/test/ladrillo_01_01.png\n",
      "Prediction - ladrillo\n",
      "\n",
      "\n",
      "dataset/test/ladrillo_01_02.png\n",
      "[[2.88846143e+02 8.23415941e+00 2.25776608e-01 9.50984180e-04\n",
      "  3.05895053e-02 9.58350176e-01]]\n",
      "Image: dataset/test/ladrillo_01_02.png\n",
      "Prediction - ladrillo\n",
      "\n",
      "\n",
      "dataset/test/ladrillo_01_06.png\n",
      "[[3.00005508e+02 8.78473219e+00 1.97383722e-01 5.04997630e-04\n",
      "  2.23629522e-02 9.49011842e-01]]\n",
      "Image: dataset/test/ladrillo_01_06.png\n",
      "Prediction - ladrillo\n",
      "\n",
      "\n",
      "dataset/test/ladrillo_01_05.png\n",
      "[[2.89249686e+02 8.86310026e+00 1.99606835e-01 5.94087637e-04\n",
      "  2.42328549e-02 9.47381840e-01]]\n",
      "Image: dataset/test/ladrillo_01_05.png\n",
      "Prediction - ladrillo\n",
      "\n",
      "\n",
      "dataset/test/pasto_04_03.png\n",
      "[[1.14673533e+03 2.62940018e+01 4.18626324e-02 1.06813878e-04\n",
      "  1.03350788e-02 5.42214287e-01]]\n",
      "Image: dataset/test/pasto_04_03.png\n",
      "Prediction - pasto\n",
      "\n",
      "\n",
      "dataset/test/ladrillo_01_03.png\n",
      "[[3.53218002e+02 9.33738869e+00 2.05010211e-01 5.47701437e-04\n",
      "  2.32438862e-02 9.50119733e-01]]\n",
      "Image: dataset/test/ladrillo_01_03.png\n",
      "Prediction - ladrillo\n",
      "\n",
      "\n",
      "dataset/test/pasto_04_04.png\n",
      "[[9.37692225e+02 2.35421468e+01 4.83159849e-02 1.18992308e-04\n",
      "  1.09056857e-02 5.98691901e-01]]\n",
      "Image: dataset/test/pasto_04_04.png\n",
      "Prediction - pasto\n",
      "\n",
      "\n",
      "dataset/test/ladrillo_01_04.png\n",
      "[[3.45843348e+02 1.00336857e+01 1.83406104e-01 3.49325314e-04\n",
      "  1.85095180e-02 9.52759851e-01]]\n",
      "Image: dataset/test/ladrillo_01_04.png\n",
      "Prediction - ladrillo\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_all_images(\"lda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[STATUS] Started extracting haralick textures..\n",
      "Processing Image - 1 in pasto\n",
      "Processing Image - 2 in pasto\n",
      "Processing Image - 3 in pasto\n",
      "Processing Image - 4 in pasto\n",
      "Processing Image - 5 in pasto\n",
      "Processing Image - 6 in pasto\n",
      "Processing Image - 7 in pasto\n",
      "Processing Image - 8 in pasto\n",
      "Processing Image - 9 in pasto\n",
      "Processing Image - 10 in pasto\n",
      "Processing Image - 11 in pasto\n",
      "Processing Image - 12 in pasto\n",
      "Processing Image - 13 in pasto\n",
      "Processing Image - 14 in pasto\n",
      "Processing Image - 1 in ladrillo\n",
      "Processing Image - 2 in ladrillo\n",
      "Processing Image - 3 in ladrillo\n",
      "Processing Image - 4 in ladrillo\n",
      "Processing Image - 5 in ladrillo\n",
      "Processing Image - 6 in ladrillo\n",
      "Processing Image - 7 in ladrillo\n",
      "Accuracy of K-NN classifier on training set: 1.00\n",
      "Image: ladrillo_02_02.png\n",
      "Prediction - ladrillo\n"
     ]
    }
   ],
   "source": [
    "train_dataset, train_labels = load_training_dataset()\n",
    "knn = knn_clasifier(train_dataset, train_labels)\n",
    "image, features = load_test_image(\"ladrillo_02_02.png\")\n",
    "prediction = knn_predict(knn, \"ladrillo_02_02.png\", image, features)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[STATUS] Started extracting haralick textures..\n",
      "Processing Image - 1 in pasto\n",
      "Processing Image - 2 in pasto\n",
      "Processing Image - 3 in pasto\n",
      "Processing Image - 4 in pasto\n",
      "Processing Image - 5 in pasto\n",
      "Processing Image - 6 in pasto\n",
      "Processing Image - 7 in pasto\n",
      "Processing Image - 8 in pasto\n",
      "Processing Image - 9 in pasto\n",
      "Processing Image - 10 in pasto\n",
      "Processing Image - 11 in pasto\n",
      "Processing Image - 12 in pasto\n",
      "Processing Image - 13 in pasto\n",
      "Processing Image - 14 in pasto\n",
      "Processing Image - 1 in ladrillo\n",
      "Processing Image - 2 in ladrillo\n",
      "Processing Image - 3 in ladrillo\n",
      "Processing Image - 4 in ladrillo\n",
      "Processing Image - 5 in ladrillo\n",
      "Processing Image - 6 in ladrillo\n",
      "Processing Image - 7 in ladrillo\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([<matplotlib.axis.XTick at 0x7f500a4d4510>,\n",
       "  <matplotlib.axis.XTick at 0x7f500a46d410>,\n",
       "  <matplotlib.axis.XTick at 0x7f500a46d810>,\n",
       "  <matplotlib.axis.XTick at 0x7f5009fd35d0>,\n",
       "  <matplotlib.axis.XTick at 0x7f5009fd3b10>],\n",
       " <a list of 5 Text xticklabel objects>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_dataset, train_labels = load_training_dataset()\n",
    "k_range = range(1, 7)\n",
    "scores = []\n",
    "for k in k_range:\n",
    "    knn = KNeighborsClassifier(n_neighbors = k)\n",
    "    knn.fit(train_dataset, train_labels)\n",
    "    scores.append(knn.score(train_dataset, train_labels))\n",
    "plt.figure()\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('accuracy')\n",
    "plt.scatter(k_range, scores)\n",
    "plt.xticks([0,1,2,3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[STATUS] Started extracting haralick textures..\n",
      "Processing Image - 1 in pasto\n",
      "Processing Image - 2 in pasto\n",
      "Processing Image - 3 in pasto\n",
      "Processing Image - 4 in pasto\n",
      "Processing Image - 5 in pasto\n",
      "Processing Image - 6 in pasto\n",
      "Processing Image - 7 in pasto\n",
      "Processing Image - 8 in pasto\n",
      "Processing Image - 9 in pasto\n",
      "Processing Image - 10 in pasto\n",
      "Processing Image - 11 in pasto\n",
      "Processing Image - 12 in pasto\n",
      "Processing Image - 13 in pasto\n",
      "Processing Image - 14 in pasto\n",
      "Processing Image - 1 in ladrillo\n",
      "Processing Image - 2 in ladrillo\n",
      "Processing Image - 3 in ladrillo\n",
      "Processing Image - 4 in ladrillo\n",
      "Processing Image - 5 in ladrillo\n",
      "Processing Image - 6 in ladrillo\n",
      "Processing Image - 7 in ladrillo\n",
      "[STATUS] Creating the classifier..\n",
      "[STATUS] Fitting data/label to model..\n",
      "Prediction - pasto\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bemesa/Documentos/Machine-learning/env/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "train_dataset, train_labels = load_training_dataset()\n",
    "svm = svm_classifier(train_dataset, train_labels)\n",
    "image, features = load_test_image(\"ladrillo_02_02.png\")\n",
    "prediction = svm_predict(svm, image, features)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
