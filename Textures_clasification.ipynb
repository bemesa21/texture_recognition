{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.feature import greycomatrix\n",
    "from skimage.feature import greycoprops\n",
    "import image_slicer\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<Tile #1 - pasto_01_01.png>,\n",
       " <Tile #2 - pasto_01_02.png>,\n",
       " <Tile #3 - pasto_01_03.png>,\n",
       " <Tile #4 - pasto_01_04.png>,\n",
       " <Tile #5 - pasto_01_05.png>,\n",
       " <Tile #6 - pasto_01_06.png>,\n",
       " <Tile #7 - pasto_01_07.png>,\n",
       " <Tile #8 - pasto_01_08.png>,\n",
       " <Tile #9 - pasto_01_09.png>,\n",
       " <Tile #10 - pasto_01_10.png>,\n",
       " <Tile #11 - pasto_01_11.png>,\n",
       " <Tile #12 - pasto_02_01.png>,\n",
       " <Tile #13 - pasto_02_02.png>,\n",
       " <Tile #14 - pasto_02_03.png>,\n",
       " <Tile #15 - pasto_02_04.png>,\n",
       " <Tile #16 - pasto_02_05.png>,\n",
       " <Tile #17 - pasto_02_06.png>,\n",
       " <Tile #18 - pasto_02_07.png>,\n",
       " <Tile #19 - pasto_02_08.png>,\n",
       " <Tile #20 - pasto_02_09.png>,\n",
       " <Tile #21 - pasto_02_10.png>,\n",
       " <Tile #22 - pasto_02_11.png>,\n",
       " <Tile #23 - pasto_03_01.png>,\n",
       " <Tile #24 - pasto_03_02.png>,\n",
       " <Tile #25 - pasto_03_03.png>,\n",
       " <Tile #26 - pasto_03_04.png>,\n",
       " <Tile #27 - pasto_03_05.png>,\n",
       " <Tile #28 - pasto_03_06.png>,\n",
       " <Tile #29 - pasto_03_07.png>,\n",
       " <Tile #30 - pasto_03_08.png>,\n",
       " <Tile #31 - pasto_03_09.png>,\n",
       " <Tile #32 - pasto_03_10.png>,\n",
       " <Tile #33 - pasto_03_11.png>,\n",
       " <Tile #34 - pasto_04_01.png>,\n",
       " <Tile #35 - pasto_04_02.png>,\n",
       " <Tile #36 - pasto_04_03.png>,\n",
       " <Tile #37 - pasto_04_04.png>,\n",
       " <Tile #38 - pasto_04_05.png>,\n",
       " <Tile #39 - pasto_04_06.png>,\n",
       " <Tile #40 - pasto_04_07.png>,\n",
       " <Tile #41 - pasto_04_08.png>,\n",
       " <Tile #42 - pasto_04_09.png>,\n",
       " <Tile #43 - pasto_04_10.png>,\n",
       " <Tile #44 - pasto_04_11.png>,\n",
       " <Tile #45 - pasto_05_01.png>,\n",
       " <Tile #46 - pasto_05_02.png>,\n",
       " <Tile #47 - pasto_05_03.png>,\n",
       " <Tile #48 - pasto_05_04.png>,\n",
       " <Tile #49 - pasto_05_05.png>,\n",
       " <Tile #50 - pasto_05_06.png>,\n",
       " <Tile #51 - pasto_05_07.png>,\n",
       " <Tile #52 - pasto_05_08.png>,\n",
       " <Tile #53 - pasto_05_09.png>,\n",
       " <Tile #54 - pasto_05_10.png>,\n",
       " <Tile #55 - pasto_05_11.png>,\n",
       " <Tile #56 - pasto_06_01.png>,\n",
       " <Tile #57 - pasto_06_02.png>,\n",
       " <Tile #58 - pasto_06_03.png>,\n",
       " <Tile #59 - pasto_06_04.png>,\n",
       " <Tile #60 - pasto_06_05.png>,\n",
       " <Tile #61 - pasto_06_06.png>,\n",
       " <Tile #62 - pasto_06_07.png>,\n",
       " <Tile #63 - pasto_06_08.png>,\n",
       " <Tile #64 - pasto_06_09.png>,\n",
       " <Tile #65 - pasto_06_10.png>,\n",
       " <Tile #66 - pasto_06_11.png>,\n",
       " <Tile #67 - pasto_07_01.png>,\n",
       " <Tile #68 - pasto_07_02.png>,\n",
       " <Tile #69 - pasto_07_03.png>,\n",
       " <Tile #70 - pasto_07_04.png>,\n",
       " <Tile #71 - pasto_07_05.png>,\n",
       " <Tile #72 - pasto_07_06.png>,\n",
       " <Tile #73 - pasto_07_07.png>,\n",
       " <Tile #74 - pasto_07_08.png>,\n",
       " <Tile #75 - pasto_07_09.png>,\n",
       " <Tile #76 - pasto_07_10.png>,\n",
       " <Tile #77 - pasto_07_11.png>,\n",
       " <Tile #78 - pasto_08_01.png>,\n",
       " <Tile #79 - pasto_08_02.png>,\n",
       " <Tile #80 - pasto_08_03.png>,\n",
       " <Tile #81 - pasto_08_04.png>,\n",
       " <Tile #82 - pasto_08_05.png>,\n",
       " <Tile #83 - pasto_08_06.png>,\n",
       " <Tile #84 - pasto_08_07.png>,\n",
       " <Tile #85 - pasto_08_08.png>,\n",
       " <Tile #86 - pasto_08_09.png>,\n",
       " <Tile #87 - pasto_08_10.png>,\n",
       " <Tile #88 - pasto_08_11.png>,\n",
       " <Tile #89 - pasto_09_01.png>,\n",
       " <Tile #90 - pasto_09_02.png>,\n",
       " <Tile #91 - pasto_09_03.png>,\n",
       " <Tile #92 - pasto_09_04.png>,\n",
       " <Tile #93 - pasto_09_05.png>,\n",
       " <Tile #94 - pasto_09_06.png>,\n",
       " <Tile #95 - pasto_09_07.png>,\n",
       " <Tile #96 - pasto_09_08.png>,\n",
       " <Tile #97 - pasto_09_09.png>,\n",
       " <Tile #98 - pasto_09_10.png>,\n",
       " <Tile #99 - pasto_09_11.png>,\n",
       " <Tile #100 - pasto_10_01.png>,\n",
       " <Tile #101 - pasto_10_02.png>,\n",
       " <Tile #102 - pasto_10_03.png>,\n",
       " <Tile #103 - pasto_10_04.png>,\n",
       " <Tile #104 - pasto_10_05.png>,\n",
       " <Tile #105 - pasto_10_06.png>,\n",
       " <Tile #106 - pasto_10_07.png>,\n",
       " <Tile #107 - pasto_10_08.png>,\n",
       " <Tile #108 - pasto_10_09.png>,\n",
       " <Tile #109 - pasto_10_10.png>,\n",
       " <Tile #110 - pasto_10_11.png>,\n",
       " <Tile #111 - pasto_11_01.png>,\n",
       " <Tile #112 - pasto_11_02.png>,\n",
       " <Tile #113 - pasto_11_03.png>,\n",
       " <Tile #114 - pasto_11_04.png>,\n",
       " <Tile #115 - pasto_11_05.png>,\n",
       " <Tile #116 - pasto_11_06.png>,\n",
       " <Tile #117 - pasto_11_07.png>,\n",
       " <Tile #118 - pasto_11_08.png>,\n",
       " <Tile #119 - pasto_11_09.png>,\n",
       " <Tile #120 - pasto_11_10.png>,\n",
       " <Tile #121 - pasto_11_11.png>)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_slicer.slice('dataset/train/pasto/pasto.jpg', 120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(image):\n",
    "    features = np.zeros(6)\n",
    "    # calculate haralick texture features for 4 types of adjacency\n",
    "    g = greycomatrix(image, [1], [0, np.pi/2], levels=256, normed=True, symmetric=True)\n",
    "    features[0] = greycoprops(g, 'contrast').mean()\n",
    "    features[1] = greycoprops(g, 'dissimilarity').mean()\n",
    "    features[2] = greycoprops(g, 'homogeneity').mean()\n",
    "    features[3] = greycoprops(g, 'ASM').mean()\n",
    "    features[4] = greycoprops(g, 'energy').mean()\n",
    "    features[5] = greycoprops(g, 'correlation').mean()\n",
    "    \n",
    "    return np.array(features)\n",
    "\n",
    "def load_training_dataset():\n",
    "    # load the training dataset\n",
    "    train_path  = \"dataset/train\"\n",
    "    train_names = os.listdir(train_path)\n",
    "\n",
    "    # empty list to hold feature vectors and train labels\n",
    "    train_features = []\n",
    "    train_labels   = []\n",
    "\n",
    "    # loop over the training dataset\n",
    "    print (\"[STATUS] Started extracting haralick textures..\")\n",
    "    for train_name in train_names:\n",
    "        cur_path = train_path + \"/\" + train_name\n",
    "        cur_label = train_name\n",
    "        i = 1\n",
    "\n",
    "        for file in glob.glob(cur_path + \"/*.png\"):\n",
    "            #print (\"Processing Image - {} in {}\".format(i, cur_label))\n",
    "            # read the training image\n",
    "            image = cv2.imread(file)\n",
    "\n",
    "            # convert the image to grayscale\n",
    "            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            # extract haralick texture from the image\n",
    "            features = extract_features(gray)\n",
    "\n",
    "            # append the feature vector and label\n",
    "            train_features.append(features)\n",
    "            train_labels.append(cur_label)\n",
    "            # show loop update\n",
    "            i += 1\n",
    "    return train_features, train_labels\n",
    "\n",
    "# loop over the test images\n",
    "\n",
    "def load_test_image(path_imagen):    \n",
    "    image = cv2.imread(path_imagen)\n",
    "    #cv2.imshow(\"Testing image \", image)\n",
    "    # convert to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    \n",
    "    # extract haralick texture from the image\n",
    "    features = extract_features(gray)\n",
    "    return image, features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_clasifier(X_train, y_train):\n",
    "    knn = KNeighborsClassifier(n_neighbors = 4)\n",
    "    knn = knn.fit(X_train, y_train)\n",
    "    print('Accuracy of K-NN classifier on training set: {:.2f}'\n",
    "      .format(knn.score(X_train, y_train)))\n",
    "    return knn\n",
    "\n",
    "def knn_predict(knn, image_name, image, features):\n",
    "    # evaluate the model and predict label\n",
    "    prediction = knn.predict(features.reshape(1, -1))[0]\n",
    "    print(\"Image: \" + image_name)\n",
    "    # show the label\n",
    "    #cv2.putText(image, prediction, (20,30), cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0,255,255), 3)\n",
    "    print (\"Prediction - {}\".format(prediction))\n",
    "    print('\\n')\n",
    "    #display the output image\n",
    "    #cv2.imshow(\"Test_Image\", image)\n",
    "    #cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def svm_classifier(X_train, y_train):\n",
    "    #create the classifier\n",
    "    print (\"[STATUS] Creating the classifier..\")\n",
    "    clf_svm = LinearSVC(random_state=9)\n",
    "\n",
    "    # fit the training data and labels\n",
    "    print (\"[STATUS] Fitting data/label to model..\")\n",
    "    return clf_svm.fit(X_train, y_train)\n",
    "    \n",
    "def svm_predict(svm, image_name, image, features):\n",
    "    # evaluate the model and predict label\n",
    "    prediction = svm.predict(features.reshape(1, -1))[0]\n",
    "    print(\"Image: \" + image_name)\n",
    "    # show the label\n",
    "    #cv2.putText(image, prediction, (20,30), cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0,255,255), 3)\n",
    "    print (\"Prediction - {}\".format(prediction))\n",
    "    print('\\n')\n",
    "    #display the output image\n",
    "    #cv2.imshow(\"Test_Image\", image)\n",
    "    #cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lda_classifier(X_train, y_train):\n",
    "    #create the classifier\n",
    "    print (\"[STATUS] Creating the classifier..\")\n",
    "    lda = LinearDiscriminantAnalysis()\n",
    "\n",
    "    # fit the training data and labels\n",
    "    print (\"[STATUS] Fitting data/label to model..\")\n",
    "    return lda.fit(X_train, y_train)\n",
    "    \n",
    "def lda_predict(lda, image_name, image, features):\n",
    "    # evaluate the model and predict label\n",
    "    print(features.reshape(1, -1))\n",
    "    prediction = lda.predict(features.reshape(1, -1))[0]\n",
    "    print(\"Image: \" + image_name)\n",
    "    # show the label\n",
    "    #cv2.putText(image, prediction, (20,30), cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0,255,255), 3)\n",
    "    print (\"Prediction - {}\".format(prediction))\n",
    "    print('\\n')\n",
    "    #display the output image\n",
    "    #cv2.imshow(\"Test_Image\", image)\n",
    "    #cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_all_images(classifier):\n",
    "    test_path = \"dataset/test\"\n",
    "    train_dataset, train_labels = load_training_dataset()\n",
    "    if(classifier == \"svm\"):\n",
    "        svm = svm_classifier(train_dataset, train_labels)\n",
    "        for file in glob.glob(test_path + \"/*.png\"):\n",
    "            print(file)\n",
    "            image, features = load_test_image(file)\n",
    "            prediction = svm_predict(svm, file, image, features)\n",
    "    elif(classifier == \"knn\"):\n",
    "        knn = knn_clasifier(train_dataset, train_labels)\n",
    "        for file in glob.glob(test_path + \"/*.png\"):\n",
    "            print(file)\n",
    "            image, features = load_test_image(file)\n",
    "            prediction = knn_predict(knn, file, image, features)\n",
    "    elif(classifier == \"lda\"):\n",
    "        lda = lda_classifier(train_dataset, train_labels)\n",
    "        for file in glob.glob(test_path + \"/*.png\"):\n",
    "            print(file)\n",
    "            image, features = load_test_image(file)\n",
    "            prediction = lda_predict(lda, file, image, features)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[STATUS] Started extracting haralick textures..\n",
      "[STATUS] Creating the classifier..\n",
      "[STATUS] Fitting data/label to model..\n",
      "dataset/test/ladrillo_01_01.png\n",
      "Image: dataset/test/ladrillo_01_01.png\n",
      "Prediction - ladrillo\n",
      "\n",
      "\n",
      "dataset/test/ladrillo_01_02.png\n",
      "Image: dataset/test/ladrillo_01_02.png\n",
      "Prediction - ladrillo\n",
      "\n",
      "\n",
      "dataset/test/pasto_01_11.png\n",
      "Image: dataset/test/pasto_01_11.png\n",
      "Prediction - ladrillo\n",
      "\n",
      "\n",
      "dataset/test/pasto_01_08.png\n",
      "Image: dataset/test/pasto_01_08.png\n",
      "Prediction - pasto\n",
      "\n",
      "\n",
      "dataset/test/pasto_01_07.png\n",
      "Image: dataset/test/pasto_01_07.png\n",
      "Prediction - pasto\n",
      "\n",
      "\n",
      "dataset/test/pasto_01_10.png\n",
      "Image: dataset/test/pasto_01_10.png\n",
      "Prediction - ladrillo\n",
      "\n",
      "\n",
      "dataset/test/pasto_01_02.png\n",
      "Image: dataset/test/pasto_01_02.png\n",
      "Prediction - ladrillo\n",
      "\n",
      "\n",
      "dataset/test/ladrillo_01_06.png\n",
      "Image: dataset/test/ladrillo_01_06.png\n",
      "Prediction - ladrillo\n",
      "\n",
      "\n",
      "dataset/test/ladrillo_01_05.png\n",
      "Image: dataset/test/ladrillo_01_05.png\n",
      "Prediction - ladrillo\n",
      "\n",
      "\n",
      "dataset/test/pasto_01_06.png\n",
      "Image: dataset/test/pasto_01_06.png\n",
      "Prediction - pasto\n",
      "\n",
      "\n",
      "dataset/test/pasto_01_03.png\n",
      "Image: dataset/test/pasto_01_03.png\n",
      "Prediction - pasto\n",
      "\n",
      "\n",
      "dataset/test/pasto_01_01.png\n",
      "Image: dataset/test/pasto_01_01.png\n",
      "Prediction - pasto\n",
      "\n",
      "\n",
      "dataset/test/pasto_01_09.png\n",
      "Image: dataset/test/pasto_01_09.png\n",
      "Prediction - pasto\n",
      "\n",
      "\n",
      "dataset/test/ladrillo_01_03.png\n",
      "Image: dataset/test/ladrillo_01_03.png\n",
      "Prediction - ladrillo\n",
      "\n",
      "\n",
      "dataset/test/pasto_02_01.png\n",
      "Image: dataset/test/pasto_02_01.png\n",
      "Prediction - ladrillo\n",
      "\n",
      "\n",
      "dataset/test/pasto_02_03.png\n",
      "Image: dataset/test/pasto_02_03.png\n",
      "Prediction - pasto\n",
      "\n",
      "\n",
      "dataset/test/ladrillo_01_04.png\n",
      "Image: dataset/test/ladrillo_01_04.png\n",
      "Prediction - ladrillo\n",
      "\n",
      "\n",
      "dataset/test/pasto_01_05.png\n",
      "Image: dataset/test/pasto_01_05.png\n",
      "Prediction - pasto\n",
      "\n",
      "\n",
      "dataset/test/pasto_02_02.png\n",
      "Image: dataset/test/pasto_02_02.png\n",
      "Prediction - ladrillo\n",
      "\n",
      "\n",
      "dataset/test/pasto_01_04.png\n",
      "Image: dataset/test/pasto_01_04.png\n",
      "Prediction - pasto\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bemesa/Documentos/Machine-learning/env/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "test_all_images(\"svm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[STATUS] Started extracting haralick textures..\n",
      "Accuracy of K-NN classifier on training set: 1.00\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.1.1) /io/opencv/modules/imgproc/src/color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-119-528a3b29b20d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_training_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mknn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mknn_clasifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_test_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ladrillo_02_02.png\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mknn_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mknn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ladrillo_02_02.png\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-93-2edbcfb1c363>\u001b[0m in \u001b[0;36mload_test_image\u001b[0;34m(path_imagen)\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;31m#cv2.imshow(\"Testing image \", image)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;31m# convert to grayscale\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     \u001b[0mgray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.1.1) /io/opencv/modules/imgproc/src/color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n"
     ]
    }
   ],
   "source": [
    "train_dataset, train_labels = load_training_dataset()\n",
    "knn = knn_clasifier(train_dataset, train_labels)\n",
    "image, features = load_test_image(\"ladrillo_02_02.png\")\n",
    "prediction = knn_predict(knn, \"ladrillo_02_02.png\", image, features)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[STATUS] Started extracting haralick textures..\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([<matplotlib.axis.XTick at 0x7fd5ab53ae50>,\n",
       "  <matplotlib.axis.XTick at 0x7fd5a0653550>,\n",
       "  <matplotlib.axis.XTick at 0x7fd5abaa0d50>,\n",
       "  <matplotlib.axis.XTick at 0x7fd5a05b1ad0>,\n",
       "  <matplotlib.axis.XTick at 0x7fd5a05b1f50>],\n",
       " <a list of 5 Text xticklabel objects>)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_dataset, train_labels = load_training_dataset()\n",
    "k_range = range(1, 7)\n",
    "scores = []\n",
    "for k in k_range:\n",
    "    knn = KNeighborsClassifier(n_neighbors = k)\n",
    "    knn.fit(train_dataset, train_labels)\n",
    "    scores.append(knn.score(train_dataset, train_labels))\n",
    "plt.figure()\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('accuracy')\n",
    "plt.scatter(k_range, scores)\n",
    "plt.xticks([0,1,2,3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[STATUS] Started extracting haralick textures..\n",
      "Processing Image - 1 in pasto\n",
      "Processing Image - 2 in pasto\n",
      "Processing Image - 3 in pasto\n",
      "Processing Image - 4 in pasto\n",
      "Processing Image - 5 in pasto\n",
      "Processing Image - 6 in pasto\n",
      "Processing Image - 7 in pasto\n",
      "Processing Image - 8 in pasto\n",
      "Processing Image - 9 in pasto\n",
      "Processing Image - 10 in pasto\n",
      "Processing Image - 11 in pasto\n",
      "Processing Image - 12 in pasto\n",
      "Processing Image - 13 in pasto\n",
      "Processing Image - 14 in pasto\n",
      "Processing Image - 1 in ladrillo\n",
      "Processing Image - 2 in ladrillo\n",
      "Processing Image - 3 in ladrillo\n",
      "Processing Image - 4 in ladrillo\n",
      "Processing Image - 5 in ladrillo\n",
      "Processing Image - 6 in ladrillo\n",
      "Processing Image - 7 in ladrillo\n",
      "[STATUS] Creating the classifier..\n",
      "[STATUS] Fitting data/label to model..\n",
      "Prediction - pasto\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bemesa/Documentos/Machine-learning/env/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "train_dataset, train_labels = load_training_dataset()\n",
    "svm = svm_classifier(train_dataset, train_labels)\n",
    "image, features = load_test_image(\"ladrillo_02_02.png\")\n",
    "prediction = svm_predict(svm, image, features)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
